{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 14 days\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "import theano\n",
    "import theano.printing as TP\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        #print 'u', shape\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor.signal.downsample as down\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, lamb = 0.1,rng=None, name=\"\"):\n",
    "        self.name = name\n",
    "        self.lamb = lamb\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState(1234)\n",
    "        self.rng = rng\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return []\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        return []\n",
    "    \n",
    "    def update(self, foo, alpha):\n",
    "        return []\n",
    "    def cost(self, gamma):\n",
    "        return 0;\n",
    "    def setInputDim(self, inputDim):\n",
    "        self.num_out = inputDim\n",
    "    def getOutputDim(self):\n",
    "        return self.num_out\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    @property\n",
    "    def moments(self):\n",
    "        return []\n",
    "    def setLambda(self, lamb):\n",
    "        self.lamb = lamb\n",
    "    \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, num_out, initW = 10., gamma  = 0.1, n = \"\", weight_init=None, bias_init=None, **kwargs):\n",
    "        super(AffineLayer, self).__init__(name= n, **kwargs)\n",
    "        self.num_out = num_out\n",
    "        if weight_init is None:\n",
    "            b = numpy.sqrt(initW / (num_out))\n",
    "            self.weight_init = Uniform(width=b)\n",
    "        if bias_init is None:\n",
    "            bias_init = Constant(0.0)\n",
    "        self.gamma= theano.shared(gamma)\n",
    "        self.b = theano.shared(Constant(0.0).generate(self.rng, (num_out)), name=self.name +\" bias\")\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]\n",
    "    @property\n",
    "    def moments(self):\n",
    "        return [self.mW, self.mb]\n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return ['W','b']\n",
    "    \n",
    "    def build(self, X):\n",
    "        #print self.name+ \" \",X.shape \n",
    "        return X.dot(self.W) + self.b\n",
    "    def cost(self, gamma):\n",
    "        return  (self.W ** 2).sum() * gamma\n",
    "    def update(self, foo, alpha):\n",
    "        gw, gb = T.grad(foo, self.parameters)\n",
    "        moments = self.lamb * self.moments -  [alpha *gw, alpha *gb]\n",
    "        self.setMoments(moments)\n",
    "        return  [(self.W, self.W + moments[0]), \n",
    "                 (self.b, self.b + moments[1])]\n",
    "    def setInputDim(self, inputDim):\n",
    "        shape = (inputDim, self.num_out)\n",
    "        print \"AffineLayer: \", shape\n",
    "        print \"AffineLayerVel : \", (shape, self.b.shape)\n",
    "        self.W = theano.shared(IsotropicGaussian(0.01).generate(self.rng, shape),name=self.name +\" weight\")\n",
    "        print self.W\n",
    "        self.mW = theano.shared(zeros_like(self.W, dtype='float32'))\n",
    "        self.mb = theano.shared(zeros_like(self.W, dtype='float32'))\n",
    "    \n",
    "class LogRegLayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(LogRegLayer, self).__init__(name = n, **kwargs)\n",
    "    def build(self, X):\n",
    "        return T.nnet.sigmoid(X)\n",
    "\n",
    "\n",
    "class TanhLayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(TanhLayer, self).__init__(name = n, **kwargs)\n",
    "    def build(self, X):\n",
    "        print \"tanh layer\", X\n",
    "        return T.tanh(X)\n",
    "\n",
    "    \n",
    "class ReLULayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(ReLULayer, self).__init__(name = n, **kwargs)\n",
    "    \n",
    "    def build(self, X):\n",
    "        return T.maximum(0.0, X)\n",
    "\n",
    "class Conv(Layer):\n",
    "    def __init__(self, f_out, f_size, initW = 10., lamb = 0.9, n = \"\", weight_init = None, **kwargs):\n",
    "        super(Conv, self).__init__(name = n, **kwargs)\n",
    "        if weight_init is None:\n",
    "            b = numpy.sqrt(initW / (f_out+ f_size + f_size))\n",
    "            self.weight_init = Uniform(width=b)\n",
    "        self.f_out = f_out\n",
    "        self.f_size = f_size\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.F, self.b]\n",
    "    @property\n",
    "    def moments(self):\n",
    "        return [self.mF, self.mb]\n",
    "    \n",
    "    def setInputDim(self, inputDim):\n",
    "        F_size = (self.f_out, ) + (inputDim[0], self.f_size, self.f_size)                                   \n",
    "        self.num_out = (self.f_out, inputDim[1] - self.f_size + 1, inputDim[2] - self.f_size + 1)\n",
    "        print 'Conv filter', F_size\n",
    "        self.F = theano.shared(IsotropicGaussian(0.01).generate(self.rng, F_size),name=self.name +\" filter\")\n",
    "        self.b = theano.shared(Constant(0.0).generate(self.rng, (self.f_out, )), name='CB')\n",
    "        self.mF = theano.shared(zeros_like(self.F, dtype='float32'), name='ConvM')\n",
    "        self.mb = theano.shared(zeros_like(self.b, dtype='float32'), name='Convb')\n",
    "    \n",
    "    \n",
    "    def update(self, foo, alpha):\n",
    "        gf, gb = theano.grad(foo, [self.F, self.b])\n",
    "        updates = []\n",
    "        self.mF= self.lamb*self.mF  -  gf\n",
    "        self.mb = self.lamb*self.mb - gb\n",
    "        F_new = self.F + self.mF\n",
    "        b_new = self.b + self.mb \n",
    "        return [(self.F, F_new), (self.b, b_new)]\n",
    "     \n",
    "    \n",
    "    def build(self, X):\n",
    "        conv = theano.tensor.nnet.conv2d(X, self.F) + self.b.dimshuffle('x',0,'x','x')\n",
    "        return theano.tensor.maximum(0.0, conv)\n",
    "        \n",
    "        \n",
    "class Flatten(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(Flatten, self).__init__(name = n, **kwargs)\n",
    "    def build(self, X):\n",
    "        return T.flatten(X, 2)\n",
    "    def setInputDim(self, inputDim):\n",
    "        out_dim = 1\n",
    "        for i in inputDim:\n",
    "            out_dim = out_dim * i\n",
    "        self.num_out = out_dim\n",
    "    \n",
    "\n",
    "class BNLayer(Layer):\n",
    "    def __init__(self,num_out, n = \"BNLayer\", gamma = 0.1, alpha=1.0,**kwargs):\n",
    "        super(BNLayer, self).__init__(name = n, **kwargs)\n",
    "        self.num_out, self.alpha = num_out, alpha\n",
    "        self.gamma= theano.shared(gamma)\n",
    "    def build(self, X):\n",
    "        self.Gamma = theano.shared(np.zeros((self.num_out,), dtype='float32'), name=(\"Gamma \" + self.name))\n",
    "        print 'Gamma shape:', np.zeros((1, self.num_out)).shape\n",
    "        self.Beta  = theano.shared(np.zeros((self.num_out,), dtype='float32'), name=(\"Beta \" + self.name))\n",
    "        print 'Beta shape:', np.zeros((1, self.num_out)).shape\n",
    "        self.Gamma.tag.initializer = Constant(1.0)\n",
    "        self.Beta.tag.initializer = Constant(0.0)\n",
    "    \n",
    "        self.means = self.alpha * theano.tensor.mean(X, 0, keepdims=True)\n",
    "        self.stds = self.alpha * theano.tensor.std(X, 0, keepdims=True)\n",
    "        self.means.tag.initializer = Constant(0.0)\n",
    "        self.stds.tag.initializer = Constant(1.0)\n",
    "        \n",
    "        normalized = theano.tensor.nnet.bn.batch_normalization(\n",
    "            X,\n",
    "            self.Gamma,\n",
    "            self.Beta,\n",
    "            self.means,\n",
    "            self.stds,\n",
    "            'high_mem'\n",
    "        )\n",
    "        return normalized\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.Gamma, self.Beta]\n",
    "    @property\n",
    "    def check(self):\n",
    "        return [self.gg, self.gb, self.Gamma, self.Beta,self.means, self.stds ]\n",
    "    #def cost(self):\n",
    "    #    return  ((self.Gamma ** 2).sum() + (self.Gamma ** 2).sum())* self.gamma\n",
    "    def update(self, foo, alpha):\n",
    "        self.gg, self.gb = T.grad(foo, self.parameters)\n",
    "        return  [(self.Gamma, self.Gamma- alpha *self.gg),\n",
    "            (self.Beta, self.Beta - alpha * self.gb)] \n",
    "    \n",
    "class SoftMaxLayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(SoftMaxLayer, self).__init__(name = n, **kwargs)\n",
    "    \n",
    "    def build(self, X):\n",
    "        return T.nnet.softmax(X)\n",
    "\n",
    "class MaxPoolLayer(Layer):\n",
    "    def __init__(self, p_size, n = \"MP\", **kwargs):\n",
    "        super(MaxPoolLayer, self).__init__(name = n, **kwargs)\n",
    "        self.p_size = p_size\n",
    "    def build(self, input):\n",
    "        return down.max_pool_2d(input, (self.p_size,self.p_size), ignore_border=True)\n",
    "    def getOutputDim(self):\n",
    "        shape = (self.num_out[0], ) + (self.num_out[1]/self.p_size, self.num_out[2]/self.p_size) \n",
    "        print \"maxPool\", shape\n",
    "        return shape\n",
    "    \n",
    "class DropOutLayer(Layer):\n",
    "    def __init__(self, dropOut = 0.1, n = \"MP\", **kwargs):\n",
    "        super(DropOutLayer, self).__init__(name = n, **kwargs)\n",
    "        self.dropOut = dropOut\n",
    "        self.u = Uniform(0.5, 1.)\n",
    "    def build(self, input):\n",
    "        self.D = theano.shared((self.u.generate(self.rng, (self.num_out,))>= self.dropOut) + 0,name=self.name +\" Dropout\") \n",
    "        print self.D.get_value()\n",
    "        return input * self.D\n",
    "    def getOutputDim(self):\n",
    "        shape = self.num_out \n",
    "        print \"maxPool\", shape\n",
    "        return shape\n",
    "    def update(self, foo, alpha):\n",
    "        return  [(self.D,\n",
    "            (self.u.generate(self.rng, (self.num_out,)) >= self.dropOut)+0)]\n",
    "    \n",
    "class FeedForwardNet(object):\n",
    "    def __init__(self, layers=None, lamb = 0.1):\n",
    "        if layers is None:\n",
    "            layers = []\n",
    "        self.layers = layers\n",
    "        self.lamb = lamb\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "    \n",
    "    @parameters.setter\n",
    "    def parameters(self, values):\n",
    "        for ownP, newP in zip(self.parameters, values):\n",
    "            ownP[...] = newP\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        param_names = []\n",
    "        for layer in self.layers:\n",
    "            param_names += layer.parameter_names\n",
    "        return param_names\n",
    "    \n",
    "    def build(self, inputDim):\n",
    "        x = T.fmatrix(\"x\")\n",
    "        y = T.vector(\"y\", dtype='int64')\n",
    "        cost = 0\n",
    "        moments = []\n",
    "        params = []\n",
    "        updates = []\n",
    "        X = x\n",
    "\n",
    "    \n",
    "        \n",
    "        alpha = theano.tensor.scalar('alpha',dtype='float32')\n",
    "        lamb = theano.tensor.scalar('alpha',dtype='float32')\n",
    "        gamma = theano.tensor.scalar('alpha',dtype='float32')\n",
    "        \n",
    "        \n",
    "        for layer, i in zip(self.layers, range(len(self.layers))):\n",
    "            layer.setInputDim(inputDim)\n",
    "            moments += layer.moments\n",
    "            params += layer.parameters\n",
    "            inputDim = layer.getOutputDim()\n",
    "            print X\n",
    "            X = layer.build(X)\n",
    "            cost += layer.cost(gamma)\n",
    "            \n",
    "        pred = np.argmax(X, 1)\n",
    "        error_rate = theano.tensor.neq(pred, y.ravel()).mean()\n",
    "        nll = -theano.tensor.log(X[theano.tensor.arange(y.shape[0]), y.ravel()]).mean() \n",
    "\n",
    "        self.costFoo = nll + cost\n",
    "            \n",
    "        grads = theano.grad(self.costFoo, params)\n",
    "        # for some reasons i have to get moments this way. \n",
    "        moments = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in params]\n",
    "\n",
    "        for p,g,v in zip(params, grads, moments):\n",
    "            print g\n",
    "            print v\n",
    "            v_new = lamb*v - alpha*g\n",
    "            print v_new\n",
    "            p_new = p + v_new\n",
    "            updates += [(v,v_new), (p,p_new)]\n",
    "\n",
    "        self.train = theano.function(inputs=[x,y, alpha, lamb, gamma], \n",
    "                                    outputs=[X, pred, self.costFoo, alpha],\n",
    "                                    updates=updates,\n",
    "                                    allow_input_downcast=True)\n",
    "        self.predict  = theano.function(inputs=[x], \n",
    "                                    outputs=pred,\n",
    "                                       allow_input_downcast=True)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def trainFunction(self):\n",
    "        return self.train\n",
    "    \n",
    "    @property\n",
    "    def predictFunction(self):\n",
    "        return self.predict\n",
    "    @property\n",
    "    def costFunction(self):\n",
    "        return self.costFoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrete_prob(arr):\n",
    "    r = random.rand()\n",
    "    cdf = 0\n",
    "    for i in arange(len(arr)):\n",
    "        cdf = cdf + arr[i]\n",
    "        if cdf > r:\n",
    "            return i\n",
    "    return len(arr) -1\n",
    "\n",
    "def generate_bank_accounts(n, start = 0): \n",
    "    x = arange(n) + start\n",
    "    random.shuffle(x)\n",
    "    return x\n",
    "\n",
    "def random_hour(n, center = 16., scale = 3, u_rate = 0.2):\n",
    "    n_norm = floor(n * (1 - u_rate));\n",
    "    u = array(uniform(0, 24, n - n_norm))\n",
    "    norm = array(random.normal(center, scale, n_norm))\n",
    "    return concatenate((norm % 24, u))\n",
    "\n",
    "def transfer_matrix(arr, p = 0.8, n = 10):\n",
    "    div = n*(n+1)/2;\n",
    "    \n",
    "    matrix = np.copy(arr)\n",
    "    random.shuffle(matrix)\n",
    "\n",
    "    for i in arange(n-1):\n",
    "        nrow = np.copy(arr)\n",
    "        random.shuffle(nrow)\n",
    "        matrix = vstack((nrow, matrix))\n",
    "        \n",
    "    matrix = vstack((arr, matrix))\n",
    "    desc = np.reshape(insert(((arange(n)+1)*p/div)[::-1], 0, 1-p), (n+1, 1))\n",
    "    \n",
    "    return hstack((desc, matrix))\n",
    "    \n",
    "def monetize(n, center = 300, shape=2):    \n",
    "    return random.gamma(shape, center, n)\n",
    "\n",
    "def make_random_transactions(accounts_num ,samples_num, susp = None):\n",
    "    \n",
    "    accounts = generate_bank_accounts(accounts_num)\n",
    "    t_m = transfer_matrix(accounts)\n",
    "    \n",
    "    probs = t_m[:,0]\n",
    "    t_m = t_m[:,1:].astype(int)\n",
    "    \n",
    "    \n",
    "    if susp == None:\n",
    "        susp = genereate_suspects(accounts)\n",
    "    \n",
    "    transactions = []\n",
    "    is_legit = [False, -1]\n",
    "    p = np.random.randint(accounts_num, size=samples_num)\n",
    "    print \"a_n: \", t_m.shape[1], \"s_n: \", samples_num\n",
    "    for i in p:\n",
    "        \n",
    "        idx = discrete_prob(probs)\n",
    "        fr = t_m[0][i]\n",
    "        to = t_m[idx,i]\n",
    "        while to == fr:\n",
    "            to = t_m[0][random.randint(accounts_num)]\n",
    "        \n",
    "        if to in susp:\n",
    "            is_legit = vstack(([False, 1], is_legit))\n",
    "        else:\n",
    "            is_legit = vstack(([True, 0], is_legit))\n",
    "            \n",
    "        if transactions == []:\n",
    "            transactions = [fr, to]\n",
    "        else:\n",
    "            transactions = vstack(([fr, to], transactions))\n",
    "        \n",
    "    \n",
    "    hours = reshape(random_hour(samples_num), (samples_num, 1))\n",
    "    monets = reshape(monetize(samples_num), (samples_num, 1))\n",
    "    \n",
    "    transactions = hstack((transactions, hours))\n",
    "    transactions = hstack((transactions, monets))\n",
    "    transactions = hstack((transactions, is_legit[:is_legit.shape[0]-1]))\n",
    "        \n",
    "    return transactions, probs, accounts, susp, t_m\n",
    "        \n",
    "        \n",
    "def genereate_cracs(accounts, cracs_num):\n",
    "    freud = []\n",
    "    f_desc = dict()\n",
    "    for victim in random.choice(accounts, cracs_num):\n",
    "        n = random.randint(5, 15)\n",
    "        h = reshape(random_hour(n, random.randint(4, 23), 0.1, 0), (n, 1))\n",
    "        m = reshape(monetize(n), (n, 1))\n",
    "        c = reshape(random.choice(accounts, n), (n, 1))\n",
    "        d = np.zeros((n, 1)) + 2 \n",
    "        \n",
    "        while victim in c:\n",
    "            c = reshape(random.choice(accounts, n), (n, 1))\n",
    "        \n",
    "        n_freud = hstack((ones((n, 1)) *victim, c, h, m, ones((n, 1)) == 0, d))\n",
    "        if freud == []:\n",
    "            freud = n_freud\n",
    "        else:\n",
    "            freud = vstack((n_freud, freud))\n",
    "        f_desc[victim] = hstack((c, h))\n",
    "\n",
    "    return freud, f_desc\n",
    "    \n",
    "def genereate_suspects(accounts, susp= 1000):\n",
    "    suspects = random.choice(accounts, susp)\n",
    "    return suspects\n",
    "    \n",
    "    \n",
    "\n",
    "def print_hist(x, b= 10, label = \"default\"):\n",
    "    hist, bins = np.histogram(x, bins=b)\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    w = 1.*(amax(x) - amin(x))/b\n",
    "    \n",
    "    plt.bar(center, hist, align='center', width=w)\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "    \n",
    "def printBar(pair1, pair2, legends=None, labels=None, title=\"\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    idx = arange(len(pair1))*4\n",
    "    b1 = ax.bar(idx, pair1, width=1, color='g')\n",
    "    b2 = ax.bar(idx+1, pair2,  width=1, color='b')\n",
    "    if labels != None: \n",
    "        ax.legend( (b1[0], b2[0]), legends )\n",
    "    if labels != None: \n",
    "        ax.set_xticks(idx+1)\n",
    "        ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_n:  10000 s_n:  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:69: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:99: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 6) (9501, 6)\n"
     ]
    }
   ],
   "source": [
    "trans_i, probs, acc, susp, t_matrix = make_random_transactions(10000, 100000)\n",
    "cracs, f_desc = genereate_cracs(acc, 1000)\n",
    "\n",
    "print trans_i.shape, cracs.shape\n",
    "trans_c = array(vstack((cracs, trans_i)))\n",
    "trans_c = array(trans_c)\n",
    "np.random.shuffle(trans_c)\n",
    "\n",
    "train_set = trans_c[:40000]\n",
    "valid_set = trans_c[40000:80000]\n",
    "test_set = trans_c[80000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_er(net):\n",
    "    predictions = net.predictFunction(valid_set[:, 2:4])\n",
    "    num_errs = 0.0 + (predictions != valid_set[:,4]).sum()\n",
    "    num_examples = 0.0 + len(valid_set[:,4])\n",
    "    return num_errs/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AffineLayer:  (2, 50)\n",
      "AffineLayerVel :  ((2, 50), Shape.0)\n",
      "x\n",
      "AffineLayer:  (50, 2)\n",
      "AffineLayerVel :  ((50, 2), Shape.0)\n",
      "Elemwise{add,no_inplace}.0\n",
      "Elemwise{add,no_inplace}.0\n",
      "Elemwise{add,no_inplace}.0\n",
      "V_tA weight\n",
      "Elemwise{sub,no_inplace}.0\n",
      "DimShuffle{1}.0\n",
      "V_tA bias\n",
      "Elemwise{sub,no_inplace}.0\n",
      "Elemwise{add,no_inplace}.0\n",
      "V_tA weight\n",
      "Elemwise{sub,no_inplace}.0\n",
      "DimShuffle{1}.0\n",
      "V_tA bias\n",
      "Elemwise{sub,no_inplace}.0\n",
      "Start\n",
      "gamma:  0\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  0 0.82615 time:  0.0652151107788\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  1 0.82615 time:  0.064915895462\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  2 0.82615 time:  0.0670251846313\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  3 0.82615 time:  0.0646409988403\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  4 0.82615 time:  0.0649237632751\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  5 0.82615 time:  0.0675609111786\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  6 0.82615 time:  0.0647950172424\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  7 0.82615 time:  0.0647578239441\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  8 0.82615 time:  0.0627489089966\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  9 0.82615 time:  0.0594937801361\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  10 0.82615 time:  0.0594229698181\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  11 0.82615 time:  0.062933921814\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  12 0.82615 time:  0.0596430301666\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  13 0.82615 time:  0.0595831871033\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  14 0.82615 time:  0.0597620010376\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  15 0.82615 time:  0.059907913208\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  16 0.82615 time:  0.0594749450684\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  17 0.82615 time:  0.0596210956573\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  18 0.82615 time:  0.0626049041748\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  19 0.82615 time:  0.0595409870148\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  20 0.82615 time:  0.0595679283142\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  21 0.82615 time:  0.061331987381\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  22 0.82615 time:  0.0594351291656\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  23 0.82615 time:  0.0596601963043\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  24 0.82615 time:  0.0614950656891\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00999999977648 nan 0.77\n",
      "After epoch:  25 0.82615 time:  0.0594120025635\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.0096394829452 nan 0.77\n",
      "After epoch:  26 0.82615 time:  0.0595481395721\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00928246509284 nan 0.77\n",
      "After epoch:  27 0.82615 time:  0.0615241527557\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00895094871521 nan 0.77\n",
      "After epoch:  28 0.82615 time:  0.0594449043274\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00864229537547 nan 0.77\n",
      "After epoch:  29 0.82615 time:  0.0594909191132\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00835421867669 nan 0.77\n",
      "After epoch:  30 0.82615 time:  0.0595991611481\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00808472838253 nan 0.77\n",
      "After epoch:  31 0.82615 time:  0.0600368976593\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.00783208012581 nan 0.77\n",
      "After epoch:  32 0.82615 time:  0.0595200061798\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00999999977648 nan 0.82\n",
      "0.0075947442092 nan 0.77\n",
      "After epoch:  33 0.82615 time:  0.0598220825195\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00983671098948 nan 0.82\n",
      "0.00737136974931 nan 0.77\n",
      "After epoch:  34 0.82615 time:  0.0613389015198\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00955566205084 nan 0.82\n",
      "0.0071607590653 nan 0.77\n",
      "After epoch:  35 0.82615 time:  0.0594880580902\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00929022673517 nan 0.82\n",
      "0.00696184905246 nan 0.77\n",
      "After epoch:  36 0.82615 time:  0.0596740245819\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00903913937509 nan 0.82\n",
      "0.00677369115874 nan 0.77\n",
      "After epoch:  37 0.82615 time:  0.0610389709473\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00880126748234 nan 0.82\n",
      "0.00659543601796 nan 0.77\n",
      "After epoch:  38 0.82615 time:  0.0595209598541\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00857559405267 nan 0.82\n",
      "0.00642632227391 nan 0.77\n",
      "After epoch:  39 0.82615 time:  0.0595850944519\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.008361203596 nan 0.82\n",
      "0.00626566400751 nan 0.77\n",
      "After epoch:  40 0.82615 time:  0.0612788200378\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00815727189183 nan 0.82\n",
      "0.00611284328625 nan 0.77\n",
      "After epoch:  41 0.82615 time:  0.0594799518585\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00796305108815 nan 0.82\n",
      "0.00596729898825 nan 0.77\n",
      "After epoch:  42 0.82615 time:  0.0594840049744\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00777786411345 nan 0.82\n",
      "0.00582852493972 nan 0.77\n",
      "After epoch:  43 0.82615 time:  0.0628788471222\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00760109443218 nan 0.82\n",
      "0.00569605827332 nan 0.77\n",
      "After epoch:  44 0.82615 time:  0.0595080852509\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00743218138814 nan 0.82\n",
      "0.00556947942823 nan 0.77\n",
      "After epoch:  45 0.82615 time:  0.0595600605011\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00727061228827 nan 0.82\n",
      "0.00544840376824 nan 0.77\n",
      "After epoch:  46 0.82615 time:  0.0594158172607\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00711591821164 nan 0.82\n",
      "0.00533248018473 nan 0.77\n",
      "After epoch:  47 0.82615 time:  0.0596609115601\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00696766981855 nan 0.82\n",
      "0.00522138690576 nan 0.77\n",
      "After epoch:  48 0.82615 time:  0.0597388744354\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00682547269389 nan 0.82\n",
      "0.00511482777074 nan 0.77\n",
      "After epoch:  49 0.82615 time:  0.0594539642334\n",
      "0.00999999977648 nan 0.85\n",
      "0.00999999977648 nan 0.87\n",
      "0.00668896315619 nan 0.82\n",
      "0.00501253129914 nan 0.77\n",
      "After epoch:  50 0.82615 time:  0.0613729953766\n",
      "0.00999999977648 nan 0.85\n",
      "0.00985318794847 nan 0.87\n",
      "0.00655780686066 nan 0.82\n",
      "0.00491424649954 nan 0.77\n",
      "After epoch:  51 0.82615 time:  0.0595989227295\n",
      "0.00999999977648 nan 0.85\n",
      "0.00966370292008 nan 0.87\n",
      "0.0064316955395 nan 0.82\n",
      "0.0048197414726 nan 0.77\n",
      "After epoch:  52 0.82615 time:  0.0593869686127\n",
      "0.00999999977648 nan 0.85\n",
      "0.00948136951774 nan 0.87\n",
      "0.00631034281105 nan 0.82\n",
      "0.00472880294546 nan 0.77\n",
      "After epoch:  53 0.82615 time:  0.0612170696259\n",
      "0.00999999977648 nan 0.85\n",
      "0.00930578820407 nan 0.87\n",
      "0.00619348464534 nan 0.82\n",
      "0.00464123254642 nan 0.77\n",
      "After epoch:  54 0.82615 time:  0.0596220493317\n",
      "0.00999999977648 nan 0.85\n",
      "0.00913659203798 nan 0.87\n",
      "0.00608087563887 nan 0.82\n",
      "0.00455684680492 nan 0.77\n",
      "After epoch:  55 0.82615 time:  0.0593807697296\n",
      "0.00999999977648 nan 0.85\n",
      "0.00897343829274 nan 0.87\n",
      "0.00597228854895 nan 0.82\n",
      "0.0044754743576 nan 0.77\n",
      "After epoch:  56 0.82615 time:  0.0611560344696\n",
      "0.00999999977648 nan 0.85\n",
      "0.0088160103187 nan 0.87\n",
      "0.00586751149967 nan 0.82\n",
      "0.00439695734531 nan 0.77\n",
      "After epoch:  57 0.82615 time:  0.0595600605011\n",
      "0.00999999977648 nan 0.85\n",
      "0.00866401009262 nan 0.87\n",
      "0.00576634751633 nan 0.82\n",
      "0.00432114768773 nan 0.77\n",
      "After epoch:  58 0.82615 time:  0.0594339370728\n",
      "0.00999999977648 nan 0.85\n",
      "0.00851716194302 nan 0.87\n",
      "0.0056686126627 nan 0.82\n",
      "0.0042479080148 nan 0.77\n",
      "After epoch:  59 0.82615 time:  0.061518907547\n",
      "0.00999999977648 nan 0.85\n",
      "0.0083752097562 nan 0.87\n",
      "0.0055741360411 nan 0.82\n",
      "0.00417710933834 nan 0.77\n",
      "After epoch:  60 0.82615 time:  0.0596590042114\n",
      "0.00999999977648 nan 0.85\n",
      "0.00823791045696 nan 0.87\n",
      "0.00548275653273 nan 0.82\n",
      "0.00410863244906 nan 0.77\n",
      "After epoch:  61 0.82615 time:  0.0594868659973\n",
      "0.00999999977648 nan 0.85\n",
      "0.0081050414592 nan 0.87\n",
      "0.00539432512596 nan 0.82\n",
      "0.00404236419126 nan 0.77\n",
      "After epoch:  62 0.82615 time:  0.0594849586487\n",
      "0.00999999977648 nan 0.85\n",
      "0.00797638949007 nan 0.87\n",
      "0.0053087011911 nan 0.82\n",
      "0.0039781993255 nan 0.77\n",
      "After epoch:  63 0.82615 time:  0.0597250461578\n",
      "0.00999999977648 nan 0.85\n",
      "0.00785175897181 nan 0.87\n",
      "0.00522575248033 nan 0.82\n",
      "0.0039160400629 nan 0.77\n",
      "After epoch:  64 0.82615 time:  0.0594198703766\n",
      "0.00999999977648 nan 0.85\n",
      "0.00773096270859 nan 0.87\n",
      "0.00514535652474 nan 0.82\n",
      "0.00385579327121 nan 0.77\n",
      "After epoch:  65 0.82615 time:  0.0595641136169\n",
      "0.00999999977648 nan 0.85\n",
      "0.00761382654309 nan 0.87\n",
      "0.00506739644334 nan 0.82\n",
      "0.0037973721046 nan 0.77\n",
      "After epoch:  66 0.82615 time:  0.061646938324\n",
      "0.00999999977648 nan 0.85\n",
      "0.00750018749386 nan 0.87\n",
      "0.00499176373705 nan 0.82\n",
      "0.00374069507234 nan 0.77\n",
      "After epoch:  67 0.82615 time:  0.0594279766083\n",
      "0.00999999977648 nan 0.85\n",
      "0.00738989049569 nan 0.87\n",
      "0.00491835549474 nan 0.82\n",
      "0.00368568487465 nan 0.77\n",
      "After epoch:  68 0.82615 time:  0.0595610141754\n",
      "0.00999999977648 nan 0.85\n",
      "0.00728279072791 nan 0.87\n",
      "0.00484707485884 nan 0.82\n",
      "0.00363226910122 nan 0.77\n",
      "After epoch:  69 0.82615 time:  0.0621919631958\n",
      "0.00999999977648 nan 0.85\n",
      "0.00717875082046 nan 0.87\n",
      "0.00477783102542 nan 0.82\n",
      "0.00358037953265 nan 0.77\n",
      "After epoch:  70 0.82615 time:  0.0594489574432\n",
      "0.00999999977648 nan 0.85\n",
      "0.00707764178514 nan 0.87\n",
      "0.00471053738147 nan 0.82\n",
      "0.00352995167486 nan 0.77\n",
      "After epoch:  71 0.82615 time:  0.0596039295197\n",
      "0.00999999977648 nan 0.85\n",
      "0.00697934115306 nan 0.87\n",
      "0.00464511336759 nan 0.82\n",
      "0.00348092452623 nan 0.77\n",
      "After epoch:  72 0.82615 time:  0.0617258548737\n",
      "0.00999999977648 nan 0.85\n",
      "0.00688373390585 nan 0.87\n",
      "0.004581481684 nan 0.82\n",
      "0.00343324057758 nan 0.77\n",
      "After epoch:  73 0.82615 time:  0.0593798160553\n",
      "0.00999999977648 nan 0.85\n",
      "0.00679071014747 nan 0.87\n",
      "0.00451956968755 nan 0.82\n",
      "0.00338684557937 nan 0.77\n",
      "After epoch:  74 0.82615 time:  0.0595190525055\n",
      "0.00999999977648 nan 0.85\n",
      "0.00670016743243 nan 0.87\n",
      "0.00445930892602 nan 0.82\n",
      "0.00334168761037 nan 0.77\n",
      "After epoch:  75 0.82615 time:  0.0619449615479\n",
      "0.00999999977648 nan 0.85\n",
      "0.00661200750619 nan 0.87\n",
      "0.00440063374117 nan 0.82\n",
      "0.00329771800898 nan 0.77\n",
      "After epoch:  76 0.82615 time:  0.0594818592072\n",
      "0.00999999977648 nan 0.85\n",
      "0.00652613723651 nan 0.87\n",
      "0.00434348266572 nan 0.82\n",
      "0.00325489044189 nan 0.77\n",
      "After epoch:  77 0.82615 time:  0.0594191551208\n",
      "0.00999999977648 nan 0.85\n",
      "0.00644246861339 nan 0.87\n",
      "0.00428779702634 nan 0.82\n",
      "0.00321316113696 nan 0.77\n",
      "After epoch:  78 0.82615 time:  0.0595579147339\n",
      "0.00999999977648 nan 0.85\n",
      "0.00636091874912 nan 0.87\n",
      "0.00423352094367 nan 0.82\n",
      "0.00317248818465 nan 0.77\n",
      "After epoch:  79 0.82615 time:  0.0598700046539\n",
      "0.00999999977648 nan 0.85\n",
      "0.00628140708432 nan 0.87\n",
      "0.004180601798 nan 0.82\n",
      "0.00313283200376 nan 0.77\n",
      "After epoch:  80 0.82615 time:  0.0595240592957\n",
      "0.00999999977648 nan 0.85\n",
      "0.0062038586475 nan 0.87\n",
      "0.00412898976356 nan 0.82\n",
      "0.00309415510856 nan 0.77\n",
      "After epoch:  81 0.82615 time:  0.0597069263458\n",
      "0.00999999977648 nan 0.85\n",
      "0.00612820219249 nan 0.87\n",
      "0.00407863594592 nan 0.82\n",
      "0.00305642164312 nan 0.77\n",
      "After epoch:  82 0.82615 time:  0.0612530708313\n",
      "0.00999999977648 nan 0.85\n",
      "0.00605436833575 nan 0.87\n",
      "0.00402949610725 nan 0.82\n",
      "0.00301959714852 nan 0.77\n",
      "After epoch:  83 0.82615 time:  0.0595099925995\n",
      "0.00999999977648 nan 0.85\n",
      "0.00598229235038 nan 0.87\n",
      "0.00398152554408 nan 0.82\n",
      "0.00298364949413 nan 0.77\n",
      "After epoch:  84 0.82615 time:  0.0595960617065\n",
      "0.00999999977648 nan 0.85\n",
      "0.00591191230342 nan 0.87\n",
      "0.00393468420953 nan 0.82\n",
      "0.00294854794629 nan 0.77\n",
      "After epoch:  85 0.82615 time:  0.0613839626312\n",
      "0.00999999977648 nan 0.85\n",
      "0.00584316952154 nan 0.87\n",
      "0.00388893205673 nan 0.82\n",
      "0.00291426246986 nan 0.77\n",
      "After epoch:  86 0.82615 time:  0.0595099925995\n",
      "0.00999999977648 nan 0.85\n",
      "0.00577600626275 nan 0.87\n",
      "0.00384423183277 nan 0.82\n",
      "0.00288076512516 nan 0.77\n",
      "After epoch:  87 0.82615 time:  0.0595531463623\n",
      "0.00999999977648 nan 0.85\n",
      "0.00571036990732 nan 0.87\n",
      "0.00380054721609 nan 0.82\n",
      "0.00284802913666 nan 0.77\n",
      "After epoch:  88 0.82615 time:  0.0609750747681\n",
      "0.00999999977648 nan 0.85\n",
      "0.00564620876685 nan 0.87\n",
      "0.00375784444623 nan 0.82\n",
      "0.00281602889299 nan 0.77\n",
      "After epoch:  89 0.82615 time:  0.0595679283142\n",
      "0.00999999977648 nan 0.85\n",
      "0.00558347301558 nan 0.87\n",
      "0.00371609069407 nan 0.82\n",
      "0.00278473971412 nan 0.77\n",
      "After epoch:  90 0.82615 time:  0.0595829486847\n",
      "0.00999999977648 nan 0.85\n",
      "0.00552211608738 nan 0.87\n",
      "0.00367525452748 nan 0.82\n",
      "0.00275413808413 nan 0.77\n",
      "After epoch:  91 0.82615 time:  0.0609381198883\n",
      "0.00999999977648 nan 0.85\n",
      "0.00546209327877 nan 0.87\n",
      "0.00363530614413 nan 0.82\n",
      "0.00272420188412 nan 0.77\n",
      "After epoch:  92 0.82615 time:  0.059522151947\n",
      "0.00999999977648 nan 0.85\n",
      "0.00540336081758 nan 0.87\n",
      "0.00359621667303 nan 0.82\n",
      "0.00269490922801 nan 0.77\n",
      "After epoch:  93 0.82615 time:  0.0599000453949\n",
      "0.00999999977648 nan 0.85\n",
      "0.00534587819129 nan 0.87\n",
      "0.00355795910582 nan 0.82\n",
      "0.00266624009237 nan 0.77\n",
      "After epoch:  94 0.82615 time:  0.0595059394836\n",
      "0.00999999977648 nan 0.85\n",
      "0.00528960581869 nan 0.87\n",
      "0.0035205068998 nan 0.82\n",
      "0.00263817445375 nan 0.77\n",
      "After epoch:  95 0.82615 time:  0.0596449375153\n",
      "0.00999999977648 nan 0.85\n",
      "0.00523450598121 nan 0.87\n",
      "0.00348383490928 nan 0.82\n",
      "0.00261069345288 nan 0.77\n",
      "After epoch:  96 0.82615 time:  0.0596890449524\n",
      "0.00999999977648 nan 0.85\n",
      "0.0051805418916 nan 0.87\n",
      "0.00344791915268 nan 0.82\n",
      "0.00258377892897 nan 0.77\n",
      "After epoch:  97 0.82615 time:  0.0593800544739\n",
      "0.00999999977648 nan 0.85\n",
      "0.00512767909095 nan 0.87\n",
      "0.00341273634695 nan 0.82\n",
      "0.00255741388537 nan 0.77\n",
      "After epoch:  98 0.82615 time:  0.061231136322\n",
      "0.00999999977648 nan 0.85\n",
      "0.00507588451728 nan 0.87\n",
      "0.00337826414034 nan 0.82\n",
      "0.00253158155829 nan 0.77\n",
      "After epoch:  99 0.82615 time:  0.0595641136169\n"
     ]
    }
   ],
   "source": [
    "features = 2\n",
    "hidden1 = 50\n",
    "outs = 2\n",
    "gamma = 0\n",
    "lamb = 0.1\n",
    "initC = 10.\n",
    "initW = 10.\n",
    "num_epochs  = 100\n",
    "\n",
    "net = FeedForwardNet([\n",
    "                      AffineLayer(hidden1, initW, gamma, \"tA\"),\n",
    "                      AffineLayer(outs, initW, gamma, \"tA\"), \n",
    "                      SoftMaxLayer(\"fSoftMax\")],lamb)\n",
    "net.build(features)\n",
    "print \"Start\"\n",
    "print \"gamma: \", gamma\n",
    "i = 0\n",
    "e = 0\n",
    "\n",
    "\n",
    "while e < num_epochs:\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    while i < train_set.shape[0]:\n",
    "        batch = train_set[i:i+100,:]\n",
    "        X = batch[:,2:4]\n",
    "        Y = batch[:,4]\n",
    "        alpha = 1e-2 * 10000 / np.maximum(10000, i/100*e)\n",
    "        x, pr ,c, a = net.trainFunction(X, Y.ravel(),alpha,lamb, gamma) #\n",
    "        i+=100\n",
    "        if i % 10000 == 0:\n",
    "            print a, c, (pr  != Y.ravel()).mean()\n",
    "    t1 = time.time()\n",
    "    print \"After epoch: \", e, compute_er(net), \"time: \", t1-t0\n",
    "    e+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: x has 4 cols (and 29501 rows) but y has 2 rows (and 50 cols)\nApply node that caused the error: Dot22(x, tA weight)\nInputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]\nInputs shapes: [(29501, 4), (2, 50)]\nInputs strides: [(16, 4), (200, 4)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-ce85e80f6798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m printBar([train_accuracy, 1 - train_accuracy],  \n\u001b[0;32m      5\u001b[0m          \u001b[1;33m[\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/os/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    607\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/os/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch: x has 4 cols (and 29501 rows) but y has 2 rows (and 50 cols)\nApply node that caused the error: Dot22(x, tA weight)\nInputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]\nInputs shapes: [(29501, 4), (2, 50)]\nInputs strides: [(16, 4), (200, 4)]\nInputs values: ['not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "test_accuracy = (net.predict(test_set[:,:4]) == test_set[:,4].ravel()).mean()\n",
    "train_accuracy = (net.predict(train_set[:,:4]) == train_set[:,4].ravel()).mean()\n",
    "\n",
    "printBar([train_accuracy, 1 - train_accuracy],  \n",
    "         [test_accuracy, 1 - test_accuracy], \n",
    "         legends = ('train', 'test'), \n",
    "         labels = ['correct', 'fail'], \n",
    "         title=\"Poprawnie/ niepoprawne \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_bank_accounts(n, start = 0): \n",
    "    x = arange(n) + start\n",
    "    random.shuffle(x)\n",
    "    return x\n",
    "\n",
    "def random_hour(n, center = 16., scale = 3, u_rate = 0.2):\n",
    "    n_norm = floor(n * (1 - u_rate));\n",
    "    u = array(uniform(0, 24, n - n_norm))\n",
    "    norm = array(random.normal(center, scale, n_norm))\n",
    "    return concatenate((norm % 24, u))\n",
    "\n",
    "def transfer_matrix(arr, p = 0.8, n = 10):\n",
    "    div = n*(n+1)/2;\n",
    "    \n",
    "    matrix = np.copy(arr)\n",
    "    random.shuffle(matrix)\n",
    "\n",
    "    for i in arange(n-1):\n",
    "        nrow = np.copy(arr)\n",
    "        random.shuffle(nrow)\n",
    "        matrix = vstack((nrow, matrix))\n",
    "        \n",
    "    matrix = vstack((arr, matrix))\n",
    "    desc = np.reshape(insert(((arange(n)+1)*p/div)[::-1], 0, 1-p), (n+1, 1))\n",
    "    \n",
    "    return hstack((desc, matrix))\n",
    "    \n",
    "def monetize(n, center = 300, shape=2):    \n",
    "    return random.gamma(shape, center, n)\n",
    "\n",
    "def make_random_transactions(accounts_num ,samples_num, susp = None):\n",
    "    \n",
    "    accounts = generate_bank_accounts(accounts_num)\n",
    "    t_m = transfer_matrix(accounts)\n",
    "    \n",
    "    probs = t_m[:,0]\n",
    "    t_m = t_m[:,1:].astype(int)\n",
    "    \n",
    "    \n",
    "    if susp == None:\n",
    "        susp = genereate_suspects(accounts)\n",
    "    \n",
    "    transactions = []\n",
    "    is_legit = [False, -1]\n",
    "    p = np.random.randint(accounts_num, size=samples_num)\n",
    "    print \"a_n: \", t_m.shape[1], \"s_n: \", samples_num\n",
    "    for i in p:\n",
    "        \n",
    "        idx = discrete_prob(probs)\n",
    "        fr = t_m[0][i]\n",
    "        to = t_m[idx,i]\n",
    "        while to == fr:\n",
    "            to = t_m[0][random.randint(accounts_num)]\n",
    "        \n",
    "        if to in susp:\n",
    "            is_legit = vstack(([False, 1], is_legit))\n",
    "        else:\n",
    "            is_legit = vstack(([True, 0], is_legit))\n",
    "            \n",
    "        if transactions == []:\n",
    "            transactions = [fr, to]\n",
    "        else:\n",
    "            transactions = vstack(([fr, to], transactions))\n",
    "        \n",
    "    \n",
    "    hours = reshape(random_hour(samples_num), (samples_num, 1))\n",
    "    monets = reshape(monetize(samples_num), (samples_num, 1))\n",
    "    \n",
    "    transactions = hstack((transactions, hours))\n",
    "    transactions = hstack((transactions, monets))\n",
    "    transactions = hstack((transactions, is_legit[:is_legit.shape[0]-1]))\n",
    "        \n",
    "    return transactions, probs, accounts, susp, t_m\n",
    "        \n",
    "        \n",
    "def genereate_cracs(accounts, cracs_num):\n",
    "    freud = []\n",
    "    f_desc = dict()\n",
    "    for victim in random.choice(accounts, cracs_num):\n",
    "        n = random.randint(5, 15)\n",
    "        h = reshape(random_hour(n, random.randint(4, 23), 0.1, 0), (n, 1))\n",
    "        m = reshape(monetize(n), (n, 1))\n",
    "        c = reshape(random.choice(accounts, n), (n, 1))\n",
    "        d = np.zeros((n, 1)) + 2 \n",
    "        \n",
    "        while victim in c:\n",
    "            c = reshape(random.choice(accounts, n), (n, 1))\n",
    "        \n",
    "        n_freud = hstack((ones((n, 1)) *victim, c, h, m, ones((n, 1)) == 0, d))\n",
    "        if freud == []:\n",
    "            freud = n_freud\n",
    "        else:\n",
    "            freud = vstack((n_freud, freud))\n",
    "        f_desc[victim] = hstack((c, h))\n",
    "\n",
    "    return freud, f_desc\n",
    "    \n",
    "def genereate_suspects(accounts, susp= 1000):\n",
    "    suspects = random.choice(accounts, susp)\n",
    "    return suspects\n",
    "    \n",
    "    \n",
    "\n",
    "def print_hist(x, b= 10, label = \"default\"):\n",
    "    hist, bins = np.histogram(x, bins=b)\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    w = 1.*(amax(x) - amin(x))/b\n",
    "    \n",
    "    plt.bar(center, hist, align='center', width=w)\n",
    "    plt.title(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_n:  10000 s_n:  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:60: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fafb5459550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trans_i, probs, acc, susp, t_matrix = make_random_transactions(10000, 100000)\n",
    "\n",
    "x = array([])\n",
    "\n",
    "for i in arange(10000):\n",
    "    x = append(x, discrete_prob(probs))\n",
    "print_hist(x, label=\"Pdp przelewow na konkretne konta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:90: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 6) (9370, 6)\n",
      "(109370, 6)\n",
      "[[  1.96900000e+03   7.73900000e+03   1.50022680e+01   8.54369536e+02\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  1.96900000e+03   1.31000000e+03   1.49460707e+01   1.04369440e+02\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  1.96900000e+03   5.36000000e+03   1.52262389e+01   4.78032451e+02\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " ..., \n",
      " [  7.12000000e+02   8.32900000e+03   2.71642955e+00   6.79408964e+02\n",
      "    1.00000000e+00   0.00000000e+00]\n",
      " [  7.91500000e+03   4.42100000e+03   6.01040198e+00   2.79900205e+02\n",
      "    1.00000000e+00   0.00000000e+00]\n",
      " [  4.43900000e+03   2.95600000e+03   8.06793528e+00   7.63320861e+01\n",
      "    1.00000000e+00   0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJFpg+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf89fa3e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cracs, f_desc = genereate_cracs(acc, 1000)\n",
    "\n",
    "print trans_i.shape, cracs.shape\n",
    "trans_c = array(vstack((cracs, trans_i)))\n",
    "print trans_c.shape\n",
    "\n",
    "print trans_c\n",
    "print_hist(trans_c[:, 4], label=\"Frauds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 6) (49370, 6)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFqlJREFUeJzt3XuwHvV93/H3BxSgDpcBO9JpJW4pyBZOU5DHclza5Li0\nXNIpMOkgy24C1ErrGggk7kyM3M5IZNpJobErpylMY2MjMbiyQmtDGoplis943IBRbIOIUUCtIxkJ\ndMBg4WBnUi7f/vGs0CPtEefK2XN43q+ZZ1j9nr38dtmzn/399vKkqpAkqd8RXVdAkjT3GA6SpBbD\nQZLUYjhIkloMB0lSi+EgSWoxHKQpSnJqkleTvO7fUZI1SX5/tuolzYT4nIMGTZJVwK8DPwO8CPw5\nsLGqbpnkfE4Fvgv8RFW9OuMVlTpky0EDJcm/Av4jcCOwqKqGgH8J/J0kP9Fp5aQ5xHDQwEhyPHAD\n8JGq+mJV/Qigqh6pql+pqpeSHJ9kY5Jnkvx5kn/dN/0RSX4nybNJ/g/wj/q++7kkf5Hkh83nL5N8\nt/lubZLbm+H9XVGXJ9nVLOfjzXeLkvwoyYl9813ejHPkrGwkqbGg6wpIs+i9wFHA3a8zzu8BxwGn\nAT8FbEnyVFV9DvgXwC8Cfxv4MfDf909UVQ8205FkAXAf8PW++R7af3sucCbwDuChJP+tqh5P8lVg\nJfBfmvF+GfivVfXKpNdWmgZbDhokbwO+3399IMn/TvKD5oz954H3A9dX1Y+rahfwCeBXmtEvA9ZX\n1VNVtQ/47cMs5z8BP6yqf3OY7wtYV1X/r6q2AY/QCxyAjfuX11zo/gBw+1RXWJoqWw4aJM8Bb0ty\nxP6AqKpzAZJ8Dxii9zfxvb5pdgGLm+G/ATx5yHcHSfJh4OeB94xTl9G+4R8DxzbDdwG3NBe7lwH7\nqupPxl81aWbZctAgeQD4K+CSMb4L8H3gJeDUvvJTgT3N8NPAyYd8d2AGyd+jd03j4qp6cSoVrKq/\nAjbTaz38MrYa1BHDQQOjql4Afgu4Ock/SXJses4G3gK8TO/A/O+a704FfoMDB+jNwLVJFjcXjT+2\nf95JTga+AFxeVf93nKpknO9vB64E/jGGgzpit5IGSlX9hyS7gd8ENgA/oveswm8Cfwxso3fN4LvA\nXwK/31yMBvg0vYvIjwAvAL8DvK/57u8DC4E7k0AvAHZW1d8aqxqv9++q+uMkrwLfqqonkTow7kNw\nSY4GvkbvLo8FwJ1VdUNz5vQFek3rncDK5syMJGuAD9E7E7uuqrY05cuB24BjgHuq6teb8qPoXYh7\nF72m/furqr/fVxooSf4XcEdVfbbrumgwjdut1PSBvq+qzgHOBi5KsgK4Hrivqt4O3A+sAUhyFr1b\n8ZYBF9Frwu9vRt8CrK6qpcDSJBc05auB56vqTGA9cNNMraA03yR5N3AOvZMvqRMTuuZQVT9uBo+m\n13ooehf1NjTlG4BLm+GLgU1V9XJV7QR2ACuSDAHHVdXWZryNfdP0z+tO4LwprY00zyW5DdhCr8X9\no46rowE2oWsOzf3W3wT+JvCfq2prkkVVNQpQVXuTLGxGX0zvrpD99jRlLwO7+8p3c+AWwcU0twhW\n1StJ9iU5qaqen+J6SfNSVV3ZdR0kmHjL4dWmW2kJvVbAOxnnoto0jXc3hyTpDTSpu5Wq6odJRoAL\ngdH9rYemy+iZZrQ9HHwv+JKm7HDl/dM81bxD5vixWg1JfIWsJE1BVU3qpHvclkOStyU5oRn+a8A/\nBLbTez/Nlc1oV9B7spOmfFWSo5KcDpwBPFRVe4EXkqxoLlBffsg0VzTDl9G7wD2mqvJTxdq1azuv\nw1z5uC3cFm6L1/9MxURaDn8d2NBcdzgC+EJV3ZPkQWBzkg/Re43Ayubg/ViSzcBj9J42vaoO1O5q\nDr6V9d6m/Fbg9iQ76L3iYNWU1kaSNCPGDYeqehRYPkb588A/OMw0v80YLyWrqm8CrYeCqne77MoJ\n1FeSNAt8fcY8NTw83HUV5gy3xQFuiwPcFtMzr34mNEnNp/pK0lyQhJrpC9KSpMFjOEiSWgwHSVKL\n4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgzSNDQ6eRpLPP0NBpXW8CzRJf\nvCfNI73fyerybyBT/vEYdccX70mSZoThIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwH\nSVKL4SBJajEcJEkthoMkqcVwkCS1jBsOSZYkuT/Jd5I8muTXmvK1SXYn+VbzubBvmjVJdiTZnuT8\nvvLlSbYleSLJ+r7yo5JsaqZ5IMkpM72ikqSJm0jL4WXgo1X1TuC9wDVJ3tF898mqWt587gVIsgxY\nCSwDLgJuTu89wwC3AKuraimwNMkFTflq4PmqOhNYD9w0EysnSZqaccOhqvZW1cPN8IvAdmBx8/VY\n7we/BNhUVS9X1U5gB7AiyRBwXFVtbcbbCFzaN82GZvhO4LwprIskaYZM6ppDktOAs4FvNEXXJHk4\nyWeSnNCULQae7JtsT1O2GNjdV76bAyHz2jRV9QqwL8lJk6mbJGnmTDgckhxL76z+uqYFcTPw01V1\nNrAX+MQM1mtSv1gkSZpZCyYyUpIF9ILh9qq6C6Cqnu0b5dPAHzbDe4CT+75b0pQdrrx/mqeSHAkc\nX1XPj1WXdevWvTY8PDzM8PDwRFZBkgbGyMgIIyMj05rHhH5DOslG4PtV9dG+sqGq2tsM/wbw7qr6\nYJKzgDuA99DrLvoKcGZVVZIHgWuBrcAfAb9bVfcmuQr4maq6Kskq4NKqWjVGPfwNaQ00f0NaUzGV\n35Aet+WQ5FzgnwKPJvk2vT3z48AHk5wNvArsBD4MUFWPJdkMPAa8BFzVd0S/GrgNOAa4Z/8dTsCt\nwO1JdgDPAa1gkCTNngm1HOYKWw4adLYcNBVTaTn4hLQkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lS\ny4SekJaknqM58JLl2bdo0ans3buzs+UPEp9zkOaRufCcQ9fL9xgweT7nIEmaEYaDJKnFcJAktRgO\nkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJ\najEcJEkthoMkqcVwkCS1GA6SpBbDQZLUMm44JFmS5P4k30nyaJJrm/ITk2xJ8niSLyc5oW+aNUl2\nJNme5Py+8uVJtiV5Isn6vvKjkmxqpnkgySkzvaKSpImbSMvhZeCjVfVO4L3A1UneAVwP3FdVbwfu\nB9YAJDkLWAksAy4Cbk6SZl63AKuraimwNMkFTflq4PmqOhNYD9w0I2snSZqSccOhqvZW1cPN8IvA\ndmAJcAmwoRltA3BpM3wxsKmqXq6qncAOYEWSIeC4qtrajLexb5r+ed0JnDedlZIkTc+krjkkOQ04\nG3gQWFRVo9ALEGBhM9pi4Mm+yfY0ZYuB3X3lu5uyg6apqleAfUlOmkzdJEkzZ8FER0xyLL2z+uuq\n6sUkdcgoh/57OnK4L9atW/fa8PDwMMPDwzO4WEma/0ZGRhgZGZnWPFI1/jE9yQLgfwD/s6o+1ZRt\nB4ararTpMvpqVS1Lcj1QVXVjM969wFpg1/5xmvJVwC9U1Uf2j1NV30hyJPB0VS0cox41kfpKb1a9\ny3dd/g10v3yPAZOXhKo67En3WCbarfRZ4LH9wdC4G7iyGb4CuKuvfFVzB9LpwBnAQ03X0wtJVjQX\nqC8/ZJormuHL6F3gluacoaHTSNLZR5ot47YckpwLfA14lN4pQwEfBx4CNgMn02sVrKyqfc00a+jd\ngfQSvW6oLU35u4DbgGOAe6rquqb8aOB24BzgOWBVczH70LrYclCnPHPvfvkeAyZvKi2HCXUrzRWG\ng7pmOHS/fI8Bk/dGditJkgaI4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+Eg\nSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS2GgySpxXCQJLUYDpKk\nFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqWXccEhya5LRJNv6ytYm2Z3kW83nwr7v1iTZkWR7\nkvP7ypcn2ZbkiSTr+8qPSrKpmeaBJKfM5ApKkiZvIi2HzwEXjFH+yapa3nzuBUiyDFgJLAMuAm5O\nkmb8W4DVVbUUWJpk/zxXA89X1ZnAeuCmqa+OJGkmjBsOVfV14AdjfJUxyi4BNlXVy1W1E9gBrEgy\nBBxXVVub8TYCl/ZNs6EZvhM4b+LVlyS9EaZzzeGaJA8n+UySE5qyxcCTfePsacoWA7v7ync3ZQdN\nU1WvAPuSnDSNekmSpmnBFKe7Gfitqqok/xb4BPCrM1SnsVokr1m3bt1rw8PDwwwPD8/QYiXpzWFk\nZISRkZFpzSNVNf5IyanAH1bVz77ed0muB6qqbmy+uxdYC+wCvlpVy5ryVcAvVNVH9o9TVd9IciTw\ndFUtPEw9aiL1ld4ovUtoXe6DLt9jwOQloape98T7UBPtVgp9Z/TNNYT9fgn402b4bmBVcwfS6cAZ\nwENVtRd4IcmK5gL15cBdfdNc0QxfBtw/mRWQJM28cbuVknweGAbemuR79FoC70tyNvAqsBP4MEBV\nPZZkM/AY8BJwVd+p/tXAbcAxwD3773ACbgVuT7IDeA5YNSNrJkmasgl1K80Vdiupa3Yrdb98jwGT\n90Z2K0mSBojhIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMk\nqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLQu6roAkTdzRze94d2PRolPZu3dnZ8uf\nTZlPP9adpOZTffXm0zswdbkPuvyulz8fj0FJqKpJpardSpKkFsNBktRiOEiSWgwHSVKL4SBJajEc\nJEkthoMkqWXccEhya5LRJNv6yk5MsiXJ40m+nOSEvu/WJNmRZHuS8/vKlyfZluSJJOv7yo9KsqmZ\n5oEkp8zkCkqSJm8iLYfPARccUnY9cF9VvR24H1gDkOQsYCWwDLgIuDkHHme8BVhdVUuBpUn2z3M1\n8HxVnQmsB26axvpIkmbAuOFQVV8HfnBI8SXAhmZ4A3BpM3wxsKmqXq6qncAOYEWSIeC4qtrajLex\nb5r+ed0JnDeF9ZAkzaCpXnNYWFWjAFW1F1jYlC8Gnuwbb09TthjY3Ve+uyk7aJqqegXYl+SkKdZL\nkjQDZurFezP5spHXff/HunXrXhseHh5meHh4BhctSfPfyMgIIyMj05rHVMNhNMmiqhptuoyeacr3\nACf3jbekKTtcef80TyU5Eji+qp4/3IL7w0GS1HboifMNN9ww6XlMtFspHHxGfzdwZTN8BXBXX/mq\n5g6k04EzgIearqcXkqxoLlBffsg0VzTDl9G7wC1J6tC4r+xO8nlgGHgrMAqsBb4E/AG9M/5dwMqq\n2teMv4beHUgvAddV1Zam/F3AbcAxwD1VdV1TfjRwO3AO8BywqrmYPVZdfGW3OuUru13+fDwGTeWV\n3f6egzQJhoPLn4/HIH/PQZI0I/yZUM0rQ0OnMTq6q+tqSG96ditpXrFbx+V3vfz5eAyyW0mSNCMM\nB0lSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS2GgySpxXCQ\nJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIklqmFQ5J\ndiZ5JMm3kzzUlJ2YZEuSx5N8OckJfeOvSbIjyfYk5/eVL0+yLckTSdZPp06SpOmbbsvhVWC4qs6p\nqhVN2fXAfVX1duB+YA1AkrOAlcAy4CLg5iRpprkFWF1VS4GlSS6YZr0kSdMw3XDIGPO4BNjQDG8A\nLm2GLwY2VdXLVbUT2AGsSDIEHFdVW5vxNvZNI0nqwHTDoYCvJNma5FebskVVNQpQVXuBhU35YuDJ\nvmn3NGWLgd195bubMklSRxZMc/pzq+rpJD8FbEnyOL3A6HfovyVJc9y0wqGqnm7++2ySLwErgNEk\ni6pqtOkyeqYZfQ9wct/kS5qyw5WPad26da8NDw8PMzw8PJ1VkKQ3nZGREUZGRqY1j1RN7cQ+yVuA\nI6rqxSQ/CWwBbgDOA56vqhuTfAw4saquby5I3wG8h1630VeAM6uqkjwIXAtsBf4I+N2quneMZdZU\n66s3h949DF3uAy5/0Jc/H49BSaiqjD/mAdNpOSwCvpikmvncUVVbkvwJsDnJh4Bd9O5QoqoeS7IZ\neAx4Cbiq70h/NXAbcAxwz1jBIEndO5oDN1nOvkWLTmXv3p2zsqwptxy6YMtBthxc/qAvfyrHwKm0\nHHxCWpLUYjhIkloMB0lSy3Sfc9CAGRo6jdHRXV1XQ9IbzAvSmhQvCLt8l+8FaUnSgLJbaR6xS0fS\nbLFbaR7pvksH5kKz2uW7/EFevt1KkqTOGA6SpBbDQZLUYjhIkloMB0lSi7eyToK3kkoaFN7KOrnl\n0/VtbN7K6vJd/mAv31tZJUmdmXfdSl3+CpMkDYp5Fw5dN+kkaRDYrSRJajEcJEkthoMkqcVwkCS1\nGA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLXMmHJJcmOTPkjyR5GNd10eSBtmcCIckRwC/B1wA\nvBP4QJJ3dFuruW6k6wrMISNdV2AOGem6AnPISNcVmNfmRDgAK4AdVbWrql4CNgGXdFynOW6k6wrM\nISNdV2AOGem6AnPISNcVmNfmSjgsBp7s+/fupkyS1IG5Eg6SpDlkTvxMaJKfA9ZV1YXNv68Hqqpu\nPGS87isrSfPQZH8mdK6Ew5HA48B5wNPAQ8AHqmp7pxWTpAE1J34JrqpeSXINsIVeV9etBoMkdWdO\ntBwkSXPLvLkg7UNyByTZmeSRJN9O8lDX9ZlNSW5NMppkW1/ZiUm2JHk8yZeTnNBlHWfLYbbF2iS7\nk3yr+VzYZR1nQ5IlSe5P8p0kjya5tikfuP1ijG3xa035pPeLedFyaB6Se4LeNYmngK3Aqqr6s04r\n1pEk3wXeVVU/6Lousy3J3wVeBDZW1c82ZTcCz1XVTc2Jw4lVdX2X9ZwNh9kWa4G/qKpPdlq5WZRk\nCBiqqoeTHAt8k95zUv+MAdsvXmdbvJ9J7hfzpeXgQ3IHC/Pn/92MqqqvA4eG4iXAhmZ4A3DprFaq\nI4fZFtDbPwZGVe2tqoeb4ReB7cASBnC/OMy22P/M2KT2i/lygPEhuYMV8JUkW5P8864rMwcsrKpR\n6P1xAAs7rk/XrknycJLPDEJXSr8kpwFnAw8CiwZ5v+jbFt9oiia1X8yXcNDBzq2q5cAvAlc33Qs6\nYO73lb5xbgZ+uqrOBvYCg9S9dCxwJ3Bdc9Z86H4wMPvFGNti0vvFfAmHPcApff9e0pQNpKp6uvnv\ns8AX6XW7DbLRJIvgtT7XZzquT2eq6tk6cCHx08C7u6zPbEmygN7B8PaquqspHsj9YqxtMZX9Yr6E\nw1bgjCSnJjkKWAXc3XGdOpHkLc1ZAUl+Ejgf+NNuazXrwsH9p3cDVzbDVwB3HTrBm9hB26I5CO73\nSwzOvvFZ4LGq+lRf2aDuF61tMZX9Yl7crQS9W1mBT3HgIbl/33GVOpHkdHqthaL3EOMdg7Qtknwe\nGAbeCowCa4EvAX8AnAzsAlZW1b6u6jhbDrMt3kevn/lVYCfw4f397m9WSc4FvgY8Su/vooCP03vT\nwmYGaL94nW3xQSa5X8ybcJAkzZ750q0kSZpFhoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+Eg\nSWr5/3Kfk9AavPQXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf8d11bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/pio/lscratch/1/os/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf8d2c3610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = random.randint(500, 1500)\n",
    "c = random.randint(0, 23)\n",
    "print n, c\n",
    "\n",
    "print_hist(random_hour(n, c, 1), label=\"wlamanie na konto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCR1MzQkSd0MDUlSt/8Phha9f7FDu7cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf895221d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_hist(trans_c[:, 3], label=\"przelane pieniadze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transaction():\n",
    "    def __init__(self, n_account, time):\n",
    "        self.n_account = n_account\n",
    "        self.time = time\n",
    "\n",
    "class Account():\n",
    "    def __init__(self, number, out_t, in_t):\n",
    "        self.in_trans = in_t\n",
    "        self.out_trans = out_t\n",
    "        self.number = number\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"To: \\n\" + self.in_trans.__str__ () + \"\\nFrom: \\n\" +self.out_trans.__str__ ()\n",
    "    \n",
    "    def isVictim(self, acc, v_p = 5):\n",
    "        t = self.out_trans[~self.out_trans['to'].isin(acc)]\n",
    "        if t[t['valid'] == False].count()[0] > v_p:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_crack(self):\n",
    "        if self.in_trans['valid'].mean() == 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def check(self, f, p=False):\n",
    "        if p:\n",
    "            print self.out_trans\n",
    "        t = self.out_trans[~self.out_trans['to'].isin(f)]\n",
    "        t = t[t['valid'] == False]\n",
    "        if p:\n",
    "            print t\n",
    "        return t['time'].std()\n",
    "    \n",
    "    def removeByhour(self, t):\n",
    "        m = t.mean()\n",
    "        s = t.std()\n",
    "        return t[(t['time'] > s - m)  and t['time'] < s + m ]\n",
    "    \n",
    "    def get_in(self):\n",
    "        return self.in_trans\n",
    "    \n",
    "    def get_out(self):\n",
    "        return self.out_trans\n",
    "    \n",
    "    def get_number(self):\n",
    "        return self.number\n",
    "        \n",
    "def makeAccounts(trans):\n",
    "    account = dict()\n",
    "    for i in arange(10000):\n",
    "        account[i] = Account(i, \n",
    "                             train_set[train_set['from'] == i], \n",
    "                             train_set[train_set['to'] == i])\n",
    "    return account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts = makeAccounts(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(train_set, accounts):\n",
    "    t_mean = train_set['time'].mean()\n",
    "    t_std = train_set['time'].std()\n",
    "    \n",
    "    susp = set()\n",
    "    stds = array([])\n",
    "    for i in accounts.keys():\n",
    "        a = accounts[i]\n",
    "        if(a.is_crack()):\n",
    "            susp.add(a.get_number())\n",
    "            \n",
    "    print len(susp)\n",
    "    for i in accounts.keys():\n",
    "        a = accounts[i]\n",
    "        if(a.isVictim(susp)):\n",
    "            std = a.check(susp)\n",
    "            if isnan(std):\n",
    "                print a\n",
    "            stds = insert(stds, 0, std)\n",
    "    return list(susp), stds\n",
    "\n",
    "def checkSusp(susp, p = False):\n",
    "    corr = 0\n",
    "    for a in susp:\n",
    "        if 1 in accounts[a].get_in()['desc_'].unique():\n",
    "            corr = corr +1\n",
    "        elif p:\n",
    "            print accounts[a]\n",
    "    return len(susp), corr            \n",
    "\n",
    "def find_frauds(accounts, susp, p_s, seprete = False):\n",
    "    by_susp = set()\n",
    "    brake_in = set()\n",
    "    for i in accounts.keys():\n",
    "        a = accounts[i]\n",
    "        if i in susp:\n",
    "            by_susp = by_susp.union(a.get_in().index)\n",
    "        if a.isVictim(susp) :\n",
    "            i = a.get_out()\n",
    "            t = i.iloc[array([i[(i['time'] < t + p_s) & (i['time'] > t - p_s)].count()[0] for t in i['time']]).argmax()]['time']\n",
    "            brake_in = brake_in.union(i[(i['time'] < t + p_s) & (i['time'] > t - p_s)].index)\n",
    "        if seprete:\n",
    "            return by_susp, brake_in\n",
    "        else:\n",
    "            return by_susp.union(brake_in)\n",
    "            \n",
    "    \n",
    "def predict(susp, std, trans_set):\n",
    "    accounts = makeAccounts(trans_set)\n",
    "    frauds = find_frauds(accounts, susp, std_param)\n",
    "    printResult(trans_set, frauds)\n",
    "    \n",
    "def printResult(i_set, frauds):\n",
    "    f = set(i_set[i_set['valid'] == False].index)\n",
    "    uf = set(i_set[i_set['valid'] == True].index)\n",
    "    print 'Liczba rzeczywistych oszustw: ', len(f)\n",
    "    print 'Liczba swierdzonych oszustw: ', len(frauds)\n",
    "    print len(f.intersection(frauds))/ float(len(f)) * 100, \"% - procent poprawnie przwidzianych oszustw\"\n",
    "    print 100 - len(f.intersection(frauds))/ float(len(f)) * 100, \"% - procent blednie przwidzianych oszustw\"\n",
    "    print len(uf.difference(frauds))/ float(len(uf)) * 100, \"% - procent przewidzianych poprawnych transakcji\"\n",
    "    print (len(uf.difference(frauds)) + len(f.intersection(frauds))) / float(len(f) + len( uf)) * 100, \"% - POPRAWNOSC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1ebc86eafbeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msusp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstd_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "susp, stds = train(train_set, accounts)\n",
    "\n",
    "std_param = stds.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_s, by_b = find_frauds(accounts, susp, std_param, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6 6\n"
     ]
    }
   ],
   "source": [
    "print len(by_s), len(by_b), len(by_s.union(by_b))\n",
    "frauds = by_s.union(by_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def printResult(i_set, frauds):\n",
    "    f = set(i_set[i_set['valid'] == False].index)\n",
    "    uf = set(i_set[i_set['valid'] == True].index)\n",
    "    print 'Liczba rzeczywistych oszustw: ', len(f)\n",
    "    print 'Liczba swierdzonych oszustw: ', len(frauds)\n",
    "    print len(f.intersection(frauds))/ float(len(f)) * 100, \"% - procent poprawnie przwidzianych oszustw\"\n",
    "    print 100 - len(f.intersection(frauds))/ float(len(f)) * 100, \"% - procent blednie przwidzianych oszustw\"\n",
    "    print len(uf.difference(frauds))/ float(len(uf)) * 100, \"% - procent przewidzianych poprawnych transakcji\"\n",
    "    print (len(uf.difference(frauds)) + len(f.intersection(frauds))) / float(len(f) + len( uf)) * 100, \"% - POPRAWNOSC\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Liczba rzeczywistych oszustw:  10285\n",
      "Liczba swierdzonych oszustw:  6\n",
      "0.0583373845406 % - procent poprawnie przwidzianych oszustw\n",
      "99.9416626155 % - procent blednie przwidzianych oszustw\n",
      "100.0 % - procent przewidzianych poprawnych transakcji\n",
      "82.8683333333 % - POPRAWNOSC\n",
      "TEST_SET\n",
      "Liczba rzeczywistych oszustw:  8548\n",
      "Liczba swierdzonych oszustw:  6\n",
      "0.0 % - procent poprawnie przwidzianych oszustw\n",
      "100.0 % - procent blednie przwidzianych oszustw\n",
      "100.0 % - procent przewidzianych poprawnych transakcji\n",
      "82.6858416042 % - POPRAWNOSC\n"
     ]
    }
   ],
   "source": [
    "print \"TRAIN SET\"\n",
    "printResult(train_set, frauds)\n",
    "print \"TEST_SET\"\n",
    "predict(susp, std_param, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: \n",
      "       from  to       time        money  valid  desc_\n",
      "14522  6512  18  23.300333  1070.195435  False      1\n",
      "18958  8328  18  14.426393  1095.833618  False      1\n",
      "48657  3805  18  12.084625   222.222168  False      1\n",
      "From: \n",
      "       from    to       time        money  valid  desc_\n",
      "11494    18  8490   4.906424   561.126160  False      2\n",
      "15632    18  7399   4.980665   292.789337  False      2\n",
      "18628    18  9673   5.003074   475.286774  False      2\n",
      "22209    18  9160   5.057663    46.375816  False      2\n",
      "30076    18  4067  16.950737   937.703430   True      0\n",
      "33286    18  2112  16.270128   250.919708   True      0\n",
      "36539    18  1123  15.083407   497.513062   True      0\n",
      "45233    18  4061   4.842069  1355.692139  False      2\n",
      "48679    18  2112  17.852150  1536.925537   True      0\n",
      "50720    18  2379  22.474735   167.710159   True      0\n",
      "54627    18  2112  20.597534  1265.736816   True      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.906424"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in [18]:\n",
    "    x = accounts[a]\n",
    "print x\n",
    "i = x.get_out()\n",
    "p_s = std_param\n",
    "i.iloc[array([i[(i['time'] < t + p_s) & (i['time'] > t - p_s)].count()[0] for t in i['time']]).argmax()]['time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', 's'], \n",
       "      dtype='|S21')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array([1, 's'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
